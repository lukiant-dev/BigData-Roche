<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" dir="ltr" lang="en-US">
<head>
<title>How-to: Use HBase Bulk Loading, and Why | Cloudera Developer Blog</title>

<meta name="keywords" content="hadoop, hadoop training, cloudera, hadoop tutorial, hadoop certification, apache hadoop, hadoop download, big data, open source" />
<meta name="description" content="" />
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<meta name="msvalidate.01" content="8857B9071A02F989DE3F8BEE557BB584" />

<link rel="search" type="application/opensearchdescription+xml" href="/assets/opensearch.xml" title="Cloudera" />

<meta property="og:title" content="How-to: Use HBase Bulk Loading, and Why"/>
<meta property="og:type" content="article"/>
<meta property="og:url" content="http://blog.cloudera.com/blog/2013/09/how-to-use-hbase-bulk-loading-and-why/"/>
<meta property="og:site_name" content="Cloudera Developer Blog"/>


<link rel="icon" href="/wp-content/themes/solutionset/assets/favicon.ico" type="image/x-icon" /> 
<link rel="stylesheet" media="all" type="text/css" href="/wp-content/themes/solutionset/assets/css/960.css?070910" />
<link rel="stylesheet" media="all" type="text/css" href="/wp-content/themes/solutionset/assets/css/reset.css?070910" />
<link rel="stylesheet" media="all" type="text/css" href="/wp-content/themes/solutionset/assets/css/all.css?20120620" />
<link rel="stylesheet" media="all" type="text/css" href="/wp-content/themes/solutionset/assets/css/wp.css?20120620" /> 

<!--[if lt IE 7]><link rel="stylesheet" type="text/css" href="http://blog.cloudera.com/wp-content/themes/solutionset/assets/css/ie6.css?20120605" media="screen"/><![endif]-->
<!--[if lt IE 8]><link rel="stylesheet" type="text/css" href="http://blog.cloudera.com/wp-content/themes/solutionset/assets/css/ie6-7.css?20120605" media="screen"/><![endif]-->
<!--[if lt IE 9]><link rel="stylesheet" type="text/css" href="http://blog.cloudera.com/wp-content/themes/solutionset/assets/css/ie.css?20120605" media="screen"/><![endif]-->

<script type="text/javascript" src="/wp-content/themes/solutionset/assets/js/modernizr-2.6.1.min.js"></script>
<script type="text/javascript" src="/wp-content/themes/solutionset/assets/js/mootools-1.2.4-yui.js"></script>
<script type="text/javascript" src="/wp-content/themes/solutionset/assets/js/mootools-1.2.4.4-more-yui.js"></script>
<script type="text/javascript" src="/wp-content/themes/solutionset/assets/js/jquery-1.6.2.min.js"></script>
<script type="text/javascript"> jQuery.noConflict(); </script>
<script type="text/javascript" src="/wp-content/themes/solutionset/assets/js/jquery.colorbox-min.js"></script>
<script type="text/javascript" src="/wp-content/themes/solutionset/assets/js/global.js?20120605"></script>
<script type="text/javascript">var switchTo5x=true;</script>
<script type="text/javascript" src="http://w.sharethis.com/button/buttons.js"></script>
<script type="text/javascript">stLight.options({publisher: "ur-aa86c136-1042-b30d-950-dd905bb179a0", doNotHash: true, doNotCopy: true, hashAddressBar: false});</script>


<link rel="pingback" href="http://blog.cloudera.com/xmlrpc.php" />
<link rel="alternate" type="application/rss+xml" title="Cloudera Developer Blog &raquo; Feed" href="http://blog.cloudera.com/feed/" />
<link rel="alternate" type="application/rss+xml" title="Cloudera Developer Blog &raquo; Comments Feed" href="http://blog.cloudera.com/comments/feed/" />
<link rel="alternate" type="application/rss+xml" title="Cloudera Developer Blog &raquo; How-to: Use HBase Bulk Loading, and Why Comments Feed" href="http://blog.cloudera.com/blog/2013/09/how-to-use-hbase-bulk-loading-and-why/feed/" />
<link rel='stylesheet' id='prettify-gc-syntax-highlighter-css'  href='http://blog.cloudera.com/wp-content/plugins/prettify-gc-syntax-highlighter/prettify.css?ver=3.3.2' type='text/css' media='all' />
<link rel='stylesheet' id='cptchStylesheet-css'  href='http://blog.cloudera.com/wp-content/plugins/captcha/css/style_wp_before_3.8.css?ver=3.3.2' type='text/css' media='all' />
<link rel="EditURI" type="application/rsd+xml" title="RSD" href="http://blog.cloudera.com/xmlrpc.php?rsd" />
<link rel="wlwmanifest" type="application/wlwmanifest+xml" href="http://blog.cloudera.com/wp-includes/wlwmanifest.xml" /> 
<link rel='prev' title='Email Indexing Using Cloudera Search' href='http://blog.cloudera.com/blog/2013/09/email-indexing-using-cloudera-search/' />
<link rel='next' title='Secrets of Cloudera Support: Impala and Search Make the Customer Experience Even Better' href='http://blog.cloudera.com/blog/2013/09/secrets-of-cloudera-support-impala-and-search-make-the-customer-experience-even-better/' />
<meta name="generator" content="WordPress 3.3.2" />
<link rel='canonical' href='http://blog.cloudera.com/blog/2013/09/how-to-use-hbase-bulk-loading-and-why/' />
<link rel='shortlink' href='http://blog.cloudera.com/?p=23407' />


<script type="text/javascript">
 var _gaq = _gaq || [];
 _gaq.push(['_setAccount', 'UA-2275969-16']);
 _gaq.push(['_trackPageview']);

 (function() {
   var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
   ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
   var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
 })();
</script>


</head>
<body class="single single-post postid-23407 single-format-standard devcenter">
			
		
			
	<header id="site-head">
<nav class="properties">
            <div class="container">
                <ul>
                    <!--<li><a href="http://www.cloudera.com">Cloudera.com</a></li>-->
                     <!--<li><a href="http://university.cloudera.com">Cloudera University</a></li>
                   <li><a href="${config.LINK_CCP}/display/DOC/Documentation">Documentation</a></li>-->
                    <li><a id="support_home_page" href="http://cloudera.com/content/support/en/home.html" class="active">Support</a></li>
                    <li><a href="http://cloudera.com/content/dev-center/en/home.html">Developers</a></li>
                  <!--<li><a href="http://cloudera.com/content/cloudera/en/partners.html">PARTNERS</a></li>-->
                   
                </ul>
                <ul class="user">
                    <li>
                       <!--<a id="signinLink" class="hidden" href="https://clouderapkb.echolane.cs3.force.com/idp/login?app=0spQ00000004CD5">Sign In</a>-->
<a id="signinLink" class="hidden" href="https://cloudera.secure.force.com">Sign In</a>
                    </li>
                    <li><a id="registerLink" class="hidden" href="http://cloudera.com/content/support/en/user-registration.html">Register</a></li>
                    <li><a href="http://cloudera.com/content/cloudera/en/about/contact-us.html">Contact Us</a></li>
                    <li><a href="http://cloudera.com/content/support/en/downloads.html">Downloads</a></li>
                    <li>
                        <div id="dropdownAction" class="dropdown" style="display:none">
                            <a id="lnkDropdowntoogle" data-toggle="dropdown" class="dropdown-toggle" href="#">

                            </a>
                            <ul aria-labelledby="dropdownMenu" tole="menu" class="dropdown-menu">
                                <li><a href="http://cloudera.com/content/support/en/edit-user-profile.html" id="editProfileLink" tabindex="-1">Edit Profile</a></li>
                                <li class="divider"></li>
                                <li>
                                <a id="logoutLink" tabindex="-1" href="#">Logout</a>
                                </script>
                                </li>
                            </ul>
                        </div>
                    </li>
                </ul>
            </div>
            <div class="bg-fix"></div>
        </nav>
<!--</div>-->

<div class="wrapper">
    <div class="bg-fix"></div>
    <h1 class="logo">
        <a href="http://cloudera.com/content/cloudera/en/home.html">Cloudera</a>
    </h1>

<nav class="site">
        <ul>
    <li class="">
 <a href="http://community.cloudera.com" data-link="external">Community</a>
</li>
<li class="">
 <a href="http://cloudera.com/content/support/en/documentation.html" data-link="external">Documentation</a>
</li>
 <li class="">
                    <a href="http://cloudera.com/content/support/en/downloads.html" data-link="external">Downloads</a>
   </li>
     <li class="">
                    <a href="http://university.cloudera.com" data-link="external">Training</a>
     </li>
<li class="">
                    <a href="http://blog.cloudera.com" data-link="external" class="active">Blogs</a>
                    <nav class="subnav menu"> <nav><ul>
<li><a href="http://vision.cloudera.com">Cloudera Vision</a></li>
<!--<li><a href="http://blog.cloudera.com/blog">Developer Blog</a></li>-->
</ul>
</nav> </nav>
</li>
            
        </ul>
    </nav>


    <div class="form-holder">
		
	    <form action="http://cloudera.com/content/cloudera/en/search.html" id="site-search" method="get" novalidate> 
	        <label for="q" class="visuallyhidden">Search</label> 
	        <input type="search" name="q" id="q" placeholder="Search"><i class="icon-search"></i> 
	    </form>
    </div>
    </div><!--</div>-->
        </header>
				
	<div role="main" class="main">
		<div class="wrapper">
			<section class="two-col">

	
<aside class="left-col">

				<nav>
			<ul class=" ">
			
								
							<li class="">
				<a
					href="http://www.cloudera.com/content/cloudera/en/why-cloudera/hadoop-and-big-data.html"
					title="Hadoop &amp; Big Data"
					class=""
					target="_blank"				>
					Hadoop &amp; Big Data				</a>

							</li>
			
					<li class="">
				<a
					href="http://www.cloudera.com/content/cloudera/en/why-cloudera/our-customers.html"
					title="Our Customers"
					class=""
					target="_blank"				>
					Our Customers				</a>

							</li>
			
					<li class="">
				<a
					href="http://www.cloudera.com/content/cloudera/en/why-cloudera/faqs.html"
					title="FAQs"
					class=""
					target="_blank"				>
					FAQs				</a>

							</li>
			
					<li class="current">
				<a
					href="/blog/"
					title="Blog"
					class="blog"
									>
					Blog				</a>

									<ul>
									<li class="">
				<a
					href="/blog/category/accumulo/"
					title="Accumulo (1)"
					class=""
									>
					Accumulo (1)				</a>

							</li>
			
					<li class="">
				<a
					href="/blog/category/avro/"
					title="Avro (16)"
					class=""
									>
					Avro (16)				</a>

							</li>
			
					<li class="">
				<a
					href="/blog/category/bigtop/"
					title="Bigtop (6)"
					class=""
									>
					Bigtop (6)				</a>

							</li>
			
					<li class="">
				<a
					href="/blog/category/books/"
					title="Books (6)"
					class=""
									>
					Books (6)				</a>

							</li>
			
					<li class="">
				<a
					href="/blog/category/careers/"
					title="Careers (14)"
					class=""
									>
					Careers (14)				</a>

							</li>
			
					<li class="">
				<a
					href="/blog/category/cdh/"
					title="CDH (127)"
					class=""
									>
					CDH (127)				</a>

							</li>
			
					<li class="">
				<a
					href="/blog/category/cloud-2/"
					title="Cloud (9)"
					class=""
									>
					Cloud (9)				</a>

							</li>
			
					<li class="">
				<a
					href="/blog/category/cloudera-life/"
					title="Cloudera Life (3)"
					class=""
									>
					Cloudera Life (3)				</a>

							</li>
			
					<li class="">
				<a
					href="/blog/category/cloudera-manager/"
					title="Cloudera Manager (61)"
					class=""
									>
					Cloudera Manager (61)				</a>

							</li>
			
					<li class="">
				<a
					href="/blog/category/community/"
					title="Community (182)"
					class=""
									>
					Community (182)				</a>

							</li>
			
					<li class="">
				<a
					href="/blog/category/data-collection/"
					title="Data Collection (17)"
					class=""
									>
					Data Collection (17)				</a>

							</li>
			
					<li class="">
				<a
					href="/blog/category/data-science/"
					title="Data Science (26)"
					class=""
									>
					Data Science (26)				</a>

							</li>
			
					<li class="">
				<a
					href="/blog/category/distribution/"
					title="Distribution (36)"
					class=""
									>
					Distribution (36)				</a>

							</li>
			
					<li class="">
				<a
					href="/blog/category/events/"
					title="Events (37)"
					class=""
									>
					Events (37)				</a>

							</li>
			
					<li class="">
				<a
					href="/blog/category/flume/"
					title="Flume (18)"
					class=""
									>
					Flume (18)				</a>

							</li>
			
					<li class="">
				<a
					href="/blog/category/general/"
					title="General (327)"
					class=""
									>
					General (327)				</a>

							</li>
			
					<li class="">
				<a
					href="/blog/category/guest/"
					title="Guest (77)"
					class=""
									>
					Guest (77)				</a>

							</li>
			
					<li class="">
				<a
					href="/blog/category/hadoop/"
					title="Hadoop (294)"
					class=""
									>
					Hadoop (294)				</a>

							</li>
			
					<li class="">
				<a
					href="/blog/category/hardware/"
					title="Hardware (3)"
					class=""
									>
					Hardware (3)				</a>

							</li>
			
					<li class="">
				<a
					href="/blog/category/hbase/"
					title="HBase (124)"
					class=""
									>
					HBase (124)				</a>

							</li>
			
					<li class="">
				<a
					href="/blog/category/hdfs/"
					title="HDFS (45)"
					class=""
									>
					HDFS (45)				</a>

							</li>
			
					<li class="">
				<a
					href="/blog/category/hive/"
					title="Hive (62)"
					class=""
									>
					Hive (62)				</a>

							</li>
			
					<li class="">
				<a
					href="/blog/category/how-to/"
					title="How-to (53)"
					class=""
									>
					How-to (53)				</a>

							</li>
			
					<li class="">
				<a
					href="/blog/category/hue/"
					title="Hue (30)"
					class=""
									>
					Hue (30)				</a>

							</li>
			
					<li class="">
				<a
					href="/blog/category/impala/"
					title="Impala (63)"
					class=""
									>
					Impala (63)				</a>

							</li>
			
					<li class="">
				<a
					href="/blog/category/kite-sdk/"
					title="Kite SDK (11)"
					class=""
									>
					Kite SDK (11)				</a>

							</li>
			
					<li class="">
				<a
					href="/blog/category/mahout-2/"
					title="Mahout (5)"
					class=""
									>
					Mahout (5)				</a>

							</li>
			
					<li class="">
				<a
					href="/blog/category/mapreduce/"
					title="MapReduce (71)"
					class=""
									>
					MapReduce (71)				</a>

							</li>
			
					<li class="">
				<a
					href="/blog/category/meet-the-engineer/"
					title="Meet The Engineer (18)"
					class=""
									>
					Meet The Engineer (18)				</a>

							</li>
			
					<li class="">
				<a
					href="/blog/category/oozie/"
					title="Oozie (25)"
					class=""
									>
					Oozie (25)				</a>

							</li>
			
					<li class="">
				<a
					href="/blog/category/ops/"
					title="Ops And DevOps (19)"
					class=""
									>
					Ops And DevOps (19)				</a>

							</li>
			
					<li class="">
				<a
					href="/blog/category/pig/"
					title="Pig (35)"
					class=""
									>
					Pig (35)				</a>

							</li>
			
					<li class="">
				<a
					href="/blog/category/quickstart-vm/"
					title="QuickStart VM (5)"
					class=""
									>
					QuickStart VM (5)				</a>

							</li>
			
					<li class="">
				<a
					href="/blog/category/search/"
					title="Search (21)"
					class=""
									>
					Search (21)				</a>

							</li>
			
					<li class="">
				<a
					href="/blog/category/security-2/"
					title="Security (15)"
					class=""
									>
					Security (15)				</a>

							</li>
			
					<li class="">
				<a
					href="/blog/category/spark/"
					title="Spark (9)"
					class=""
									>
					Spark (9)				</a>

							</li>
			
					<li class="">
				<a
					href="/blog/category/sqoop/"
					title="Sqoop (20)"
					class=""
									>
					Sqoop (20)				</a>

							</li>
			
					<li class="">
				<a
					href="/blog/category/support/"
					title="Support (4)"
					class=""
									>
					Support (4)				</a>

							</li>
			
					<li class="">
				<a
					href="/blog/category/testing/"
					title="Testing (8)"
					class=""
									>
					Testing (8)				</a>

							</li>
			
					<li class="">
				<a
					href="/blog/category/this-month-in-the-ecosystem/"
					title="This Month In The Ecosystem (8)"
					class=""
									>
					This Month In The Ecosystem (8)				</a>

							</li>
			
					<li class="">
				<a
					href="/blog/category/tools/"
					title="Tools (6)"
					class=""
									>
					Tools (6)				</a>

							</li>
			
					<li class="">
				<a
					href="/blog/category/training-2/"
					title="Training (42)"
					class=""
									>
					Training (42)				</a>

							</li>
			
					<li class="">
				<a
					href="/blog/category/use-case/"
					title="Use Case (59)"
					class=""
									>
					Use Case (59)				</a>

							</li>
			
					<li class="">
				<a
					href="/blog/category/whirr/"
					title="Whirr (6)"
					class=""
									>
					Whirr (6)				</a>

							</li>
			
					<li class="">
				<a
					href="/blog/category/yarn/"
					title="YARN (13)"
					class=""
									>
					YARN (13)				</a>

							</li>
			
					<li class="">
				<a
					href="/blog/category/zookeeper/"
					title="ZooKeeper (24)"
					class=""
									>
					ZooKeeper (24)				</a>

							</li>
			
					<li class="">
				<a
					href="/archive/"
					title="Archives by Month"
					class=""
									>
					Archives by Month				</a>

							</li>
			
							</ul>
							</li>
			
						
			    
			
				<div style="clear:both"></div>
			</ul>
			</nav>
			<div class="menu-special">
				<ul>
							
				
				
		
				
		
				
				
				
				

		
					</ul>
			</div>
			
</aside>


<section>
			<h1 class="heading ">How-to: Use HBase Bulk Loading, and Why</h1>
			
			<script type="text/javascript" src="http://platform.twitter.com/widgets.js"></script>
			
			<ul class="post-info">
				<li>by Jean-Daniel (JD) Cryans</li>
				<li>September 27, 2013</li>
				<li class="comment"><a href="#comments">1 comment</a></li>
				
			</ul>
			
			<div class="text-block">
				<p><a href="http://hbase.apache.org">Apache HBase</a> is all about giving you random, real-time, read/write access to your Big Data, but how do you efficiently get that data into HBase in the first place? Intuitively, a new user will try to do that via the client APIs or by using a MapReduce job with TableOutputFormat, but those approaches are problematic, as you will learn below. Instead, the HBase bulk loading feature is much easier to use and can insert the same amount of data more quickly.</p>
<p>This blog post will introduce the basic concepts of the bulk loading feature, present two use cases, and propose two examples.</p>
<h2>Overview of Bulk Loading</h2>
<p>If you have any of these symptoms, bulk loading is probably the right choice for you:</p>
<ul>
<li>You needed to tweak your MemStores to use most of the memory.</li>
<li>You needed to either use bigger WALs or bypass them entirely.</li>
<li>Your compaction and flush queues are in the hundreds.</li>
<li>Your GC is out of control because your inserts range in the MBs.</li>
<li>Your latency goes out of your SLA when you import data.</li>
</ul>
<p>Most of those symptoms are commonly referred to as “growing pains.” Using bulk loading can help you avoid them.<br />  <br /> In HBase-speak, bulk loading is the process of preparing and loading <a href="http://blog.cloudera.com/blog/2012/06/hbase-io-hfile-input-output/">HFiles</a> (HBase’s own file format) directly into the RegionServers, thus bypassing the <a href="http://blog.cloudera.com/blog/2012/06/hbase-write-path/">write path</a> and obviating those issues entirely. This process is similar to ETL and looks like this:</p>
<p><strong>1. Extract the data from a source, typically text files or another database. </strong>HBase doesn’t manage this part of the process. In other words, you cannot tell HBase to prepare HFiles by directly reading them from MySQL &#8212; rather, you have to do it by your own means. For example, you could run mysqldump on a table and upload the resulting files to HDFS or just grab your Apache HTTP log files. In any case, your data needs to be in HDFS before the next step.</p>
<p><strong>2. Transform the data into HFiles. </strong>This step requires a MapReduce job and for most input types you will have to write the Mapper yourself. The job will need to emit the row key as the Key, and either a KeyValue, a Put, or a Delete as the Value. The Reducer is handled by HBase; you configure it using HFileOutputFormat.configureIncrementalLoad() and it does the following:</p>
<ul>
<li>Inspects the table to configure a total order partitioner</li>
<li>Uploads the partitions file to the cluster and adds it to the DistributedCache</li>
<li>Sets the number of reduce tasks to match the current number of regions</li>
<li>Sets the output key/value class to match HFileOutputFormat&#8217;s requirements</li>
<li>Sets the reducer up to perform the appropriate sorting (either KeyValueSortReducer or PutSortReducer)</li>
</ul>
<p>At this stage, one HFile will be created per region in the output folder. Keep in mind that the input data is almost completely re-written, so you will need at least twice the amount of disk space available than the size of the original data set. For example, for a 100GB mysqldump you should have at least 200GB of available disk space in HDFS. You can delete the dump file at the end of the process.</p>
<p><strong>3. Load the files into HBase by telling the RegionServers where to find them. </strong>This is the easiest step. It requires using LoadIncrementalHFiles (more commonly known as the <a href="http://hbase.apache.org/book.html#completebulkload">completebulkload</a> tool), and by passing it a URL that locates the files in HDFS, it will load each file into the relevant region via the RegionServer that serves it. In the event that a region was split after the files were created, the tool will automatically split the HFile according to the new boundaries. This process isn’t very efficient, so if your table is currently being written to by other processes, it’s best to get the files loaded as soon as the transform step is done. </p>
<p>Here’s an illustration of this process. The data flow goes from the original source to HDFS, where the RegionServers will simply move the files to their regions’ directories.</p>
<p align="center"><a href="http://blog.cloudera.com/wp-content/uploads/2013/09/cryans.png"><img title="cryans" src="http://blog.cloudera.com/wp-content/uploads/2013/09/cryans.png" alt="" width="500" height="210" /></a></p>
<h2>Use Cases</h2>
<p><strong>Original dataset load:</strong> All users migrating from another datastore should consider this use case. First, you have to go through the exercise of <a href="http://hbase.apache.org/book/schema.casestudies.html">designing the table schema</a> and then create the table itself, pre-split. The split points have to take into consideration the row-key distribution and the number of RegionServers. I recommend reading my colleague Lars George’s <a href="http://www.slideshare.net/cloudera/hadoop-world-2011-advanced-hbase-schema-design-lars-george-cloudera">presentation on advanced schema design</a> for any serious use case.</p>
<p>The advantage here is that it is much faster to write the files directly than going through the RegionServer’s write path (writing to both the MemStore and the WAL) and then eventually flushing, compacting, and so on. It also means you don’t have to tune your cluster for a write-heavy workload and then tune it again for your normal workload.</p>
<p><strong>Incremental load: </strong>Let’s say that you have some dataset currently being served by HBase, but now you need to import more data in batch from a third party or you have a nightly job that generates a few gigabytes that you need to insert. It’s probably not as large as the dataset that HBase is already serving, but it might affect your latency’s 95th percentile. Going through the normal write path will have the adverse effect of triggering more flushes and compactions during the import than normal. This additional IO stress will compete with your latency-sensitive queries.</p>
<h2>Examples</h2>
<p>You can use the following examples in your own Hadoop cluster but the instructions are provided for the <a href="http://www.cloudera.com/content/dev-center/en/home/developer-admin-resources/quickstart-vm.html">Cloudera QuickStart VM</a>, which is a single-node cluster, guest OS, and sample data and examples baked into a virtual machine appliance for your desktop.<br />  <br />Once you start the VM, tell it, via the web interface that will automatically open, to deploy CDH and then make sure that the HBase service is also started.</p>
<p><strong>Built-in TSV Bulk Loader</strong></p>
<p>HBase ships with a MR job that can read a delimiter-separated values file and output directly into an HBase table or create HFiles for bulk loading. Here we are going to:</p>
<ol>
<li>Get the sample data and upload it to HDFS.</li>
<li>Run the ImportTsv job to transform the file into multiple HFiles according to a pre-configured table.</li>
<li>Prepare and load the files in HBase.</li>
</ol>
<p>The first step is to open a console and use the following command to get sample data:<br />  </p>
<pre class="code" style="padding-left: 10px;">curl -O
<a href="https://people.apache.org/~jdcryans/word_count.csv">https://people.apache.org/~jdcryans/word_count.csv</a>
</pre>
<p>&nbsp;</p>
<p>I created this file by running a word count on the original manuscript of this very blog post and then outputting the result in csv format, without any column titles. Now, upload the file to HDFS:<br /> </p>
<pre class="code" style="padding-left: 10px;">hdfs dfs -put word_count.csv </pre>
<p>&nbsp;</p>
<p>The extraction part of the bulk load now being complete, you need to transform the file. First you need to design the table. To keep things simple, call it “wordcount” &#8212; the row keys will be the words themselves and the only column will contain the count, in a family that we’ll call “f”. The best practice when creating a table is to split it according to the row key distribution but for this example we’ll just create five regions with split points spread evenly across the key space. Open the hbase shell:<br /> </p>
<pre class="code" style="padding-left: 10px;">hbase shell </pre>
<p>&nbsp;</p>
<p>And run the following command to create the table:<br /> </p>
<pre class="code" style="padding-left: 10px;">create 'wordcount', {NAME =&gt; 'f'},   {SPLITS =&gt; ['g', 'm', 'r', 'w']} </pre>
<p>&nbsp;</p>
<p>The four split points will generate five regions, where the first region starts with an empty row key. To get better split points you could also do a quick analysis to see how the words are truly distributed, but I’ll leave that up to you.</p>
<p>If you point your VM’s browser to http://localhost:60010/ you will see our newly created table and its five regions all assigned to the RegionServer.</p>
<p>Now it’s time to do the heavy lifting. Invoking the HBase jar on the command line with the “hadoop” script will show a list of available tools. The one we want is called importtsv and has the following usage:</p>
<pre class="code" style="padding-left: 10px;">hadoop jar /usr/lib/hbase/hbase-0.94.6-cdh4.3.0-security.jar importtsv
 ERROR: Wrong number of arguments: 0
 Usage: importtsv -Dimporttsv.columns=a,b,c &lt;tablename&gt; &lt;inputdir&gt;
</pre>
<p>&nbsp;</p>
<p>The command line we are going to use is the following one:</p>
<pre class="code" style="padding-left: 10px;">hadoop jar   /usr/lib/hbase/hbase-0.94.6-cdh4.3.0-
security.jar importtsv
-Dimporttsv.separator=,
-Dimporttsv.bulk.output=output
-Dimporttsv.columns=HBASE_ROW_KEY,f:count wordcount word_count.csv
</pre>
<p>&nbsp;</p>
<p>Here’s a rundown of the different configuration elements:</p>
<ul>
<li><strong>-Dimporttsv.separator=,</strong> specifies that the separator is a comma.</li>
<li><strong>-Dimporttsv.bulk.output=output</strong> is a relative path to where the HFiles will be written. Since your user on the VM is “cloudera” by default, it means the files will be in /user/cloudera/output. Skipping this option will make the job write directly to HBase.</li>
<li><strong>-Dimporttsv.columns=HBASE_ROW_KEY,f:count</strong> is a list of all the columns contained in this file. The row key needs to be identified using the all-caps HBASE_ROW_KEY string; otherwise it won’t start the job. (I decided to use the qualifier “count” but it could be anything else.)</li>
</ul>
<p>The job should complete within a minute, given the small input size. Note that five Reducers are running, one per region. Here’s the result on HDFS:<br /> </p>
<pre class="code" style="padding-left: 10px;">-rw-r--r--   3 cloudera cloudera         4265   2013-09-12 13:13 output/f/2c0724e0c8054b70bce11342dc91897b
-rw-r--r--   3 cloudera cloudera         3163   2013-09-12 13:14 output/f/786198ca47ae406f9be05c9eb09beb36
-rw-r--r--   3 cloudera cloudera         2487   2013-09-12 13:14 output/f/9b0e5b2a137e479cbc978132e3fc84d2
-rw-r--r--   3 cloudera cloudera         2961   2013-09-12 13:13 output/f/bb341f04c6d845e8bb95830e9946a914
-rw-r--r--   3 cloudera cloudera         1336   2013-09-12 13:14 output/f/c656d893bd704260a613be62bddb4d5f
</pre>
<p>&nbsp;</p>
<p>As you can see, the files currently belong to the user “cloudera”. In order to load them we need to change the owner to “hbase” or HBase won’t have the permission to move the files. Run the following command:</p>
<pre class="code" style="padding-left: 10px;">sudo -u hdfs hdfs dfs -chown -R   hbase:hbase/user/cloudera/output
</pre>
<p>&nbsp;</p>
<p>For the final step, we need to use the completebulkload tool to point to where the files are and which tables we are loading to:<br /> </p>
<pre class="code" style="padding-left: 10px;">hbase org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles output wordcount </pre>
<p>&nbsp;</p>
<p>Going back into the HBase shell, you can run the count command that will show you how many rows were loaded. If you forgot to chown, the command will hang.</p>
<p><strong>Custom MR Job</strong></p>
<p>The TSV bulk loader is good for prototyping, but because it interprets everything as strings and doesn’t support manipulating the fields at transformation time, you will end up having to write your own MR job. My colleague James Kinley, who works as a solutions architect in Europe, wrote such a job that we’re going to use for our next example. The data for the job contains public Facebook and Twitter messages related to the 2010 NBA Finals (game 1) between the Lakers and the Celtics. You can find the code <a href="https://github.com/jrkinley/hbase-bulk-import-example">here</a>. (The Quick Start VM comes with git and maven installed so you can clone the repository on it.)<br />  <br /> Looking at the Driver class, the most important bits are the following:<br />  </p>
<pre class="code" style="padding-left: 10px;">job.setMapOutputKeyClass(ImmutableBytesWritable.class);
    job.setMapOutputValueClass(KeyValue.class);
…
	// Auto configure partitioner and reducer
    HFileOutputFormat.configureIncrementalLoad(job, hTable);
    </pre>
<p>&nbsp;</p>
<p>First, your Mapper needs to output a ImmutableBytesWritable that contains the row key, and the output value can be either a KeyValue, a Put, or a Delete. The second snippet shows how to configure the Reducer; it is in fact completely handled by HFileOutputFormat. configureIncrementalLoad() as described in the “Transform” section previously.<br />  <br /> The HBaseKVMapper class only contains the Mapper that respects the configured output key and values:<br /> </p>
<pre class="code" style="padding-left: 10px;">public class HBaseKVMapper extends
   Mapper&lt;LongWritable,   Text, ImmutableBytesWritable,
KeyValue&gt; { </pre>
<p>&nbsp;</p>
<p>In order to run it you’ll need to compile the project using maven and grab the data files following the links in the README. (It also contains the shell script to create the table.) Before starting the job, don’t forget to upload the files to HDFS and to set your classpath to be aware of HBase because you’re not going to use its jar this time:<br /> </p>
<pre class="code" style="padding-left: 10px;">export HADOOP_CLASSPATH=$HADOOP_CLASSPATH:/etc/hbase/conf/:/usr/lib/hbase/*
</pre>
<p>&nbsp;</p>
<p>You’ll be able to start the job using a command line similar to this one:<br /> </p>
<pre class="code" style="padding-left: 10px;">hadoop jar hbase-examples-0.0.1-SNAPSHOT.jar
com.cloudera.examples.hbase.bulkimport.Driver -libjars
/home/cloudera/.m2/repository/joda-time/joda-time/2.1/joda-time-2.1.jar,
/home/cloudera/.m2/repository/net/sf/opencsv/opencsv/2.3/opencsv-2.3.jar
RowFeeder\ for\ Celtics\ and\ Lakers\ Game\ 1.csv output2 NBAFinal2010
</pre>
<p>&nbsp;</p>
<p>As you can see, the job’s dependencies have to be added separately. Finally, you can load the files by first changing their owner and then running the completebulkload tool:<br /> </p>
<pre class="code" style="padding-left: 10px;">sudo -u hdfs hdfs dfs -chown -R hbase:hbase/user/cloudera/output2
hbase org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles output2 NBAFinal2010 </pre>
<p>&nbsp;</p>
<h2>Potential Issues</h2>
<p><strong>Recently deleted data reappearing.</strong> This issue happens when a Delete is inserted via a bulk load and is major compacted while the corresponding Put is still in a MemStore. The data will be considered deleted when the Delete is in an HFile but, once it’s removed during the compaction, the Put will become visible again. If you have such a use case, consider configuring your column families to keep the deleted cells with KEEP_DELETED_CELLS in the shell or HColumnDescriptor.setKeepDeletedCells().<br />  <br /> <strong>Bulk-loaded data cannot be overwritten by another bulk load.</strong> This issue occurs when two bulk-loaded HFiles loaded at different times try to write a different value in the same cell, meaning that they have the same row key, family, qualifier, and timestamp. The result is that the first inserted value will be returned instead of the second one. This bug will be fixed in HBase 0.96.0 and CDH 5 (the next CDH major version) and work is being done in <a href="https://issues.apache.org/jira/browse/HBASE-8521">HBASE-8521</a> for the 0.94 branch and CDH 4.</p>
<p><strong>Bulk loading triggers major compactions.</strong> This issue comes up when you&#8217;re doing incremental bulk loads and there are enough bulk-loaded files to trigger a minor compaction (the default threshold being 3). The HFiles are loaded with a sequence number set to 0 so they get picked up first when the RegionServer is selecting files for a compaction, and due to a bug it will also select all the remaining files. This issue will seriously affect those who already have big regions (multiple GBs) or who bulk load often (every few hours and less) as a lot of data will be compacted. HBase 0.96.0 has the proper fix and so will CDH 5; <a href="https://issues.apache.org/jira/browse/HBASE-8521">HBASE-8521</a> fixes the issue in 0.94 as the bulk-loaded HFiles are now assigned a proper sequence number. <a href="https://issues.apache.org/jira/browse/HBASE-8283">HBASE-8283</a> can be enabled with hbase.hstore.useExploringCompation after 0.94.9 and CDH 4.4.0 to mitigate this issue by just being a smarter compaction-selection algorithm.</p>
<p><strong>Bulk-loaded data isn’t replicated</strong>. As bulk loading bypasses the write path, the WAL doesn’t get written to as part of the process. Replication works by reading the WAL files so it won’t see the bulk loaded data – and the same goes for the edits that use Put.setWriteToWAL(true). One way to handle that is to ship the raw files or the HFiles to the other cluster and do the other processing there.</p>
<h2>Conclusion</h2>
<p>The goal of this blog post was to introduce you to Apache HBase bulk loading’s basic concepts. We explained how the process is like doing ETL, and that it is much better for big data sets than using the normal API since it bypasses the write path. The two examples were included to show how simple TSV files can be bulk loaded to HBase and how to write your own Mapper for other data formats.<br />  <br /> Now you can try doing the same using a<a href="http://gethue.tumblr.com/post/58181985680/hadoop-tutorial-how-to-create-example-tables-in-hbase"> graphical user interface via Hue</a>.</p>
<p><em>Jean-Daniel (JD) Cryans is a software engineer at Cloudera and an HBase Committer/PMC Member.</em><br />  </p>

				<div class="social-buttons">
<span class='st_facebook_large' displayText='Facebook'></span>
<span class='st_twitter_large' displayText='Tweet'></span>
<span class='st_linkedin_large' displayText='LinkedIn'></span>
<span class='st_googleplus_large' displayText='Google +'></span>
<span class='st_email_large' displayText='Email'></span>
				</div>
			</div>

			<div class="grid_2" style="margin:0">
  <div class="comments comments-2">
    <div class="field-under">
      <h4>Filed under:</h4>
      <ul class="post-categories">
	<li><a href="http://blog.cloudera.com/blog/category/hbase/" title="View all posts in HBase" rel="category tag">HBase</a></li>
	<li><a href="http://blog.cloudera.com/blog/category/how-to/" title="View all posts in How-to" rel="category tag">How-to</a></li></ul>  	</div>
  	
  <a name="comments"></a>
  <div class="comments-head">
    <strong>1 Response</strong>
   
  </div>
  <ul class="comments-list">
  	<li>
		<em class="comment-date">
			<a rel="nofollow" href="">VJ</a> /
			December 04, 2013 / 1:48 PM		</em>
		<p>Any actual experience of someone having deployed and performed such a process in production environment?</p>
<p>-VJ</p>
	</li>
</li>
  </ul>
  <a name="leave-comment"></a>
  <form action="/wp-comments-post.php" method="POST">
  	<div class="comment-form">
  		<h4>Leave a comment</h4>
  		<div class="row">
  			<input type="text" value="" class="txt" name="author"/>
  			<label>Name <span>required</span></label>
  		</div>
  		<div class="row">
  			<input type="text" value="" class="txt" name="email"/>
  			<label class="published">Email <span>required</span> <em>(will not be published)</em></label>
  		</div>
  		<div class="row">
  			<input type="text" value="" class="txt" name="url"/>
  			<label>Website</label>
  		</div>
  		<div class="row">
  			<textarea rows="10" cols="30" class="area" name="comment"></textarea>
  			<label>Comment</label>
  		</div>
  		<fieldset>
  			<input type="button" value="Leave Comment" class="btn cta"/>
  		</fieldset>
  	</div>
  	<input type='hidden' name='comment_post_ID' value='23407' id='comment_post_ID' />
<input type='hidden' name='comment_parent' id='comment_parent' value='0' />
  	<p class="cptch_block"><label>Prove you're human!<span class="required"> *</span></label><br />		<input type="hidden" name="cptch_result" value="D7c=" />
		<input type="hidden" name="cptch_time" value="1398162677" />
		<input type="hidden" value="Version: 2.4" />
		t&#119;o &times; 4 =  <input id="cptch_input" type="text" autocomplete="off" name="cptch_number" value="" maxlength="2" size="2" aria-required="true" required="required" style="margin-bottom:0;display:inline;font-size: 12px;width: 40px;" />	</p>  </form>
</div></section>




<!-- Google Code for New Remarketing Pixel -->
<!-- Remarketing tags may not be associated with personally identifiable information or placed on pages related to sensitive categories. For instructions on adding this tag and more information on the above requirements, read the setup guide: google.com/ads/remarketingsetup -->
<script type="text/javascript">
/* <![CDATA[ */
var google_conversion_id = 1035979479;
var google_conversion_label = "xel9CJ-P0QMQ15X_7QM";
var google_custom_params = window.google_tag_params;
var google_remarketing_only = true;
/* ]]> */
</script>
<script type="text/javascript" src="//www.googleadservices.com/pagead/conversion.js">
</script>

<noscript>
<div style="display:inline;"> <img height="1" width="1" style="border-style:none;" alt="" src="//googleads.g.doubleclick.net/pagead/viewthroughconversion/1035979479/?value=0&label=xel9CJ-P0QMQ15X_7QM&guid=ON&script=0"/> </div>
</noscript>
</section>
<span class="bg-fix"></span>
</div>
</div>
<footer id="global-footer">
<div class="footerContent parbase">
<footer>
  <div class="wrapper">
    <div class="bg-fix"></div>
    <nav>
      <ul>
        <li class="section"><a href="http://www.cloudera.com/content/cloudera/en/products-and-services.html">Products</a></li>
        <li><a href="http://www.cloudera.com/content/cloudera/en/products/cloudera-enterprise.html">Cloudera Enterprise</a></li>
        <li><a href="http://www.cloudera.com/content/cloudera/en/products-and-services/cloudera-express.html">Cloudera Express</a></li>
        <li><a href="http://www.cloudera.com/content/cloudera/en/products-and-services/cloudera-enterprise/cloudera-manager.html">Cloudera Manager</a></li>
        <li><a href="http://www.cloudera.com/content/cloudera/en/products-and-services/cdh.html">CDH</a></li>
        <li><a href="http://www.cloudera.com/content/support/en/downloads.html">All Downloads</a></li>
        <li><a href="http://www.cloudera.com/content/cloudera/en/products-and-services/professional-services.html">Professional Services</a></li>
        <li><a href="http://www.cloudera.com/content/cloudera/en/training.html">Training</a></li>
      </ul>
      <ul>
        <li class="section"><a href="http://www.cloudera.com/content/cloudera/en/solutions.html">Solutions</a></li>
        <li><a href="http://www.cloudera.com/content/cloudera/en/solutions/enterprise-solutions.html">Enterprise Solutions</a></li>
        <li><a href="http://www.cloudera.com/content/cloudera/en/solutions/partner.html">Partner Solutions</a></li>
        <li><a href="http://www.cloudera.com/content/cloudera/en/solutions/industries.html">Industry Solutions</a></li>
      </ul>
      <ul>
        <li class="section"><a href="http://www.cloudera.com/content/cloudera/en/partners.html">Partners</a></li>
        <li class="section"><a href="http://www.cloudera.com/content/cloudera/en/resources/library.html">Resource Library</a></li>
        <li class="section"><a href="https://ccp.cloudera.com/display/SUPPORT/Get+Support">Support</a></li>
      </ul>
      <ul>
        <li class="section"><a href="http://www.cloudera.com/content/cloudera/en/about.html">About</a></li>
        <li><a href="http://www.cloudera.com/content/cloudera/en/about/hadoop-and-big-data.html">Hadoop &amp; Big Data</a></li>
        <li><a href="http://www.cloudera.com/content/cloudera/en/about/management.html">Management Team</a></li>
        <li><a href="http://www.cloudera.com/content/cloudera/en/about/board.html">Board</a></li>
        <li><a href="http://www.cloudera.com/content/cloudera/en/about/events.html">Events</a></li>
        <li><a href="http://www.cloudera.com/content/cloudera/en/about/press-center.html">Press Center</a></li>
        <li><a href="http://www.cloudera.com/content/cloudera/en/about/careers.html">Careers</a></li>
        <li><a href="http://www.cloudera.com/content/cloudera/en/about/contact-form.html">Contact Us</a></li>
        <li><a href="http://www.cloudera.com/content/cloudera/en/subscription-center.html">Subscription Center</a></li>
      </ul>
      <div class="locale-and-social" style="float:right">
        <div>
          <div class="locale-and-social">
            <div class="locale">
              <select onchange="this.options[this.selectedIndex].value &amp;&amp; (window.location = this.options[this.selectedIndex].value);" class="site-language">
                <option value="http://www.cloudera.com" name="English">English</option>
                <option value="http://www.cloudera.co.jp/">Japanese</option>
              </select>
            </div>
            <div class="social"><span class="follow">Follow us:</span><span class="share">Share:<i class="icon-share"></i></span>
              <ul>
                <li><a class="linkedIn" target="_blank" href="http://www.linkedin.com/company/cloudera">LinkedIn</a></li>
                <li><a class="twitter" target="_blank" href="http://twitter.com/cloudera">Twitter</a></li>
                <li><a class="facebook" target="_blank" href="http://www.facebook.com/cloudera">Facebook</a></li>
                <li><a class="youtube" target="_blank" href="http://www.youtube.com/user/clouderahadoop">YouTube</a></li>
              </ul>
            </div>
          </div>
        </div>
      </div>
    </nav>
    <nav class="global-footer"><span class="logo"><a>Cloudera</a></span>
      <address>
      <span>Cloudera, Inc.</span> <span><a target="_blank" href="http://www.google.com/maps?q=1001+Page+Mill+Rd,+Palo+Alto,+CA+94306">1001 Page Mill Road Bldg 2</a></span> <span>Palo Alto, CA 94304</span>
      </address>
      <address>
      <span><a href="http://www.cloudera.com">www.cloudera.com</a></span> <span>US: 1-888-789-1488</span> <span>Intl: 1-650-362-0488</span>
      </address>
      <div class="copyright"><span><span class="piped">©2014 Cloudera, Inc. All rights reserved</span><span class="piped"><a href="http://www.cloudera.com/content/cloudera/en/terms-of-service.html">Terms &amp; Conditions</a></span><a href="http://www.cloudera.com/content/cloudera/en/privacy-policy.html">Privacy Policy</a></span> <span>Hadoop and the Hadoop elephant logo are trademarks of the <a target="_blank" href="http://www.apache.org/">Apache Software Foundation</a>.</span></div>
    </nav>
  </div>
</footer>
<script type='text/javascript' src='http://blog.cloudera.com/wp-content/plugins/prettify-gc-syntax-highlighter/prettify.js?ver=3.3.2'></script>
<script type='text/javascript' src='http://blog.cloudera.com/wp-content/plugins/prettify-gc-syntax-highlighter/launch.js?ver=3.3.2'></script>
<div class="modal" style="display:none">
  <div id="password-required">
    <div class="inner"> </div>
  </div>
</div>
<div class="tooltip" class="tooltip" style="display:none">
</div>
<script type="text/javascript" src="http://dnn506yrbagrg.cloudfront.net/pages/scripts/0011/2160.js"></script>
<script type="text/javascript">var _kiq = _kiq || [];</script> 
<script type="text/javascript" src="http://s3.amazonaws.com/ki.js/14646/2Sr.js" async></script>
</body></html>
